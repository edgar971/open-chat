# ---- Base Node ----
FROM node:19-alpine AS base
WORKDIR /app
COPY /ui/package*.json ./

# ---- Dependencies ----
FROM base AS dependencies
RUN npm ci

# ---- Build ----
FROM dependencies AS build
COPY /ui .
RUN npm run build

# ---- Production ----
FROM nvidia/cuda:12.2.0-devel-ubuntu22.04

ENV DEBIAN_FRONTEND=noninteractive
ENV HOST=0.0.0.0
ENV CUDA_DOCKER_ARCH=all
ENV LLAMA_CUBLAS=1
ENV OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXXXXXX
ENV OPENAI_API_HOST=http://localhost:8000
ENV N_GPU_LAYERS=16

WORKDIR /app

COPY --from=dependencies /app/node_modules ./node_modules
COPY --from=build /app/.next ./.next
COPY --from=build /app/public ./public
COPY --from=build /app/package*.json ./
COPY --from=build /app/next.config.js ./next.config.js
COPY --from=build /app/next-i18next.config.js ./next-i18next.config.js

# Install system dependencies
# Install Node.js 19.x
RUN apt-get update && apt-get install -y --assume-yes \
    wget python3-pip curl \
    && rm -rf /var/lib/apt/lists/* \
    && wget -qO- https://deb.nodesource.com/setup_19.x | bash - \ 
    && apt-get install -y nodejs \
    && CMAKE_ARGS="-DLLAMA_CUBLAS=on" FORCE_CMAKE=1 pip install llama-cpp-python==0.2.11 \
    && pip install numpy==1.25.2 diskcache==5.6.1 uvicorn==0.23.2 fastapi==0.101.1 sse-starlette==1.6.5 starlette-context==0.3.6 pydantic-settings==2.0.3 \
    && rm -rf /var/lib/apt/lists/* \
    && mkdir -p /etc/OpenCL/vendors && echo "libnvidia-opencl.so.1" > /etc/OpenCL/vendors/nvidia.icd \
    && apt-get clean  \
    && mkdir -p /models

COPY ./run.sh ./run.sh

# Expose any necessary ports
EXPOSE 3000 8000

# Entrypoint or CMD to start your application
CMD ["/bin/sh", "/app/run.sh"]

